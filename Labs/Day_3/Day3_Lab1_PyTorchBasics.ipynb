{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KamP67nRt-Ko"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRn1N6ZuHHg"
      },
      "source": [
        "#**Lab: Pytorch Basics**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZXwf7gKK_Ia"
      },
      "source": [
        "## **What is Pytorch?** <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/PyTorch_logo_icon.svg/500px-PyTorch_logo_icon.svg.png\" width=\"4%\">\n",
        "\n",
        "\n",
        "**PyTorch** is an open-source deep learning framework that allows us to build and train neural networks using **tensors** and **automatic differentiation**.  \n",
        "It provides simple, flexible tools to define models, compute gradients using backpropagation, and optimize parameters efficiently.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMLes6srWwMe"
      },
      "source": [
        "## üì¶ **Tensors in PyTorch**\n",
        "\n",
        "A **tensor** is the main data structure in PyTorch.  \n",
        "It is similar to a NumPy array, but can run on both CPUs and GPUs.\n",
        "\n",
        "Tensors are used to represent: input data, model parameters, and model outputs\n",
        "\n",
        "### üîπ Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_R5-1UJaw0w",
        "outputId": "71bd0aa6-f3ac-4363-d2b6-f7357c1dfa83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([1., 2., 3.])\n",
            "y: tensor([ 1.6098, -0.3975,  0.5459])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.randn(3)\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1boO-_nua7dB"
      },
      "source": [
        "### üîπ Tensor Shapes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDn9esxa_o_",
        "outputId": "4e21c384-5784-425d-c523-0736af515b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x:\", x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfrk3ELobLIP"
      },
      "source": [
        "### üîπ Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Krsxjc3bYqo",
        "outputId": "e7ed7736-2243-4d31-e254-6e3681cc11f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: tensor([5., 7., 9.])\n",
            "Multiplication: tensor([ 4., 10., 18.])\n",
            "Matrix multiplication result shape: torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "# Element-wise operations\n",
        "print(\"Addition:\", a + b)\n",
        "print(\"Multiplication:\", a * b)\n",
        "\n",
        "# Matrix multiplication\n",
        "A = torch.randn(2, 3)\n",
        "B = torch.randn(3, 2)\n",
        "C = A @ B\n",
        "\n",
        "print(\"Matrix multiplication result shape:\", C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rYObkabicO"
      },
      "source": [
        "\n",
        "\n",
        "> See! just like Numpy Arrays, but more powerful!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOtVHO3WY_-"
      },
      "source": [
        "---\n",
        "## üìä **Data Representation in Deep Learning**\n",
        "\n",
        "The way data is represented depends on whether it is **structured (tabular)** or **unstructured (images)**.\n",
        "\n",
        "### üîπ1Ô∏è‚É£ **Tabular Data (Structured Data)**\n",
        "Tabular data consists of rows and columns.\n",
        "\n",
        "Each row represents a sample and each column represents a feature.\n",
        "\n",
        "- Represented as a **2D tensor**\n",
        "- Shape: `(batch_size, number_of_features)`\n",
        "- Commonly used for tasks like regression and classification\n",
        "\n",
        "Example:\n",
        "- Features: age, salary, debt  \n",
        "- Tensor shape: `(N, 3)`\n",
        "\n",
        "### üîπ2Ô∏è‚É£ **Image Data (Unstructured Data)**\n",
        "Image data is unstructured and contains spatial information.\n",
        "\n",
        "- Represented as a **4D tensor**\n",
        "- Shape: `(batch_size, channels, height, width)`\n",
        "- Channels represent color information:\n",
        "  - Grayscale ‚Üí 1 channel\n",
        "  - RGB ‚Üí 3 channels\n",
        "\n",
        "Example:\n",
        "- RGB image of size 224√ó224  \n",
        "- Tensor shape: `(N, 3, 224, 224)`\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27NITm3aWla9"
      },
      "source": [
        "## üìå **How to Change Dimensions in PyTorch?**\n",
        "\n",
        "Manipulating tensor shapes is essential in deep learning. PyTorch provides several functions to modify tensor dimensions.\n",
        "\n",
        "### **üîπ 1Ô∏è‚É£ Flatten**\n",
        "- Converts **any shape** to `(batch_size, features)`.\n",
        "- **Example:**  \n",
        "  `(batch_size, channels, height, width) ‚Üí (batch_size, features)`\n",
        "\n",
        "### **üîπ 2Ô∏è‚É£ Squeeze**\n",
        "- **Removes dimensions** with size `1`.\n",
        "- **Example:**  \n",
        "  `(1, 32, 3, 28, 28) ‚Üí (32, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 3Ô∏è‚É£ Unsqueeze**\n",
        "- **Adds a dimension** with size `1` at a specified position.\n",
        "- **Example:**  \n",
        "  `(3, 28, 28) ‚Üí (1, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 4Ô∏è‚É£ View (works similar to reshape)**\n",
        "- **Reshapes a tensor freely** while maintaining the same number of elements.\n",
        "- **Example:**  \n",
        "  `(32, 3, 28, 28) ‚Üí view(-1, 3*28*28) ‚Üí (32, 3*28*28)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY0z_-JwRYWk",
        "outputId": "dd654eb0-86a2-4cca-d1e2-5119e5453357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flatten: torch.Size([32, 2352])\n",
            "Squeeze: torch.Size([3, 28, 28])\n",
            "Unsqueeze: torch.Size([1, 3, 28, 28])\n",
            "View: torch.Size([32, 2352])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1Ô∏è‚É£ Flatten - Convert any shape to (batch_size, features)\n",
        "# convert from 4d to 2d\n",
        "x = torch.randn(32, 3, 28, 28) #(num of sample, rdg,h,w)\n",
        "x_flat = x.flatten(start_dim=1)# with out thing in () well multi all dim to gather\n",
        "print(\"Flatten:\", x_flat.shape)  # (32, 2352) row and column\n",
        "\n",
        "# 2Ô∏è‚É£ Squeeze - Remove dimensions with size 1\n",
        "x = torch.randn(1, 3, 28, 28)\n",
        "x_sq = x.squeeze()\n",
        "print(\"Squeeze:\", x_sq.shape)  # (3, 28, 28)\n",
        "\n",
        "# 3Ô∏è‚É£ Unsqueeze - Add a new dimension of size 1\n",
        "x = torch.randn(3, 28, 28)\n",
        "x_unsq = x.unsqueeze(0) #add to first posision\n",
        "print(\"Unsqueeze:\", x_unsq.shape)  # (1, 3, 28, 28)\n",
        "\n",
        "# 4Ô∏è‚É£ View - Reshape freely while keeping same number of elements\n",
        "x = torch.randn(32, 28, 28, 3)\n",
        "x_view = x.view(32, -1)  # Flatten all except batch\n",
        "print(\"View:\", x_view.shape)  # (32, 28*28*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q98MVwNxvNwL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrCEfnNborH"
      },
      "source": [
        "## üìå **Changing Data Type or Moving Data/Model to CPU/GPU**  \n",
        "\n",
        "PyTorch allows you to **change the datatype** of a tensor and **move it between CPU and GPU** using `.to()`.  \n",
        "\n",
        "\n",
        "### üîπ **Change Datatype**\n",
        "Use `.to(dtype)` to convert a tensor's data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAQnY7HWYlG",
        "outputId": "ce1bbf7a-fc54-4962-ff34-cf871dcb2c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a float32 tensor\n",
        "x = torch.tensor([1.2, 2.3, 3.4], dtype=torch.float32)\n",
        "print(x.dtype)  # Output: torch.float32\n",
        "\n",
        "# Convert to float16\n",
        "x_half = x.to(torch.float16)\n",
        "print(x_half.dtype)  # Output: torch.float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MOJ8tx0ceVL"
      },
      "source": [
        "### üîπ **Move Tensors to GPU (if available)**\n",
        "**GPUs are faster and more efficient** in most cases when training or inferencing deep learning models.\n",
        "\n",
        "Use `.to(device)` to move a tensor to GPU for faster computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iv00vultxnB",
        "outputId": "7497b5f2-c3cc-45cd-e838-d54c11341e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Automatically select CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create a tensor and move it to GPU\n",
        "x_gpu = x.to(device)\n",
        "print(x_gpu.device)  # Output: cuda:0 (if GPU is available) or cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEVOLXed3ut"
      },
      "source": [
        "Note: When training a model, always move BOTH the model and data to the same device. Otherwise, you will get an error like this:\n",
        "\n",
        "`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8DN_nVlUbod"
      },
      "source": [
        "## **üìå PyTorch Workflow Organization**\n",
        "\n",
        "### **It consists of 4 main components:**\n",
        "1Ô∏è‚É£ **Dataset Class**  \n",
        "- Handles loading and preprocessing data.  \n",
        "- Converts raw data (e.g., images, CSVs) into model-ready tensors.  \n",
        "\n",
        "2Ô∏è‚É£ **Model Class**  \n",
        "- Defines the architecture of your neural network (e.g., layers, activations).  \n",
        "\n",
        "3Ô∏è‚É£ **Training Loop**  \n",
        "- Updates model weights using backpropagation and optimizers.  \n",
        "- Computes the loss for every batch and adjusts the parameters to minimize it.  \n",
        "\n",
        "4Ô∏è‚É£ **Validation Loop**  \n",
        "- Evaluates the model's performance on a validation set.  \n",
        "- Does not update weights but computes metrics like accuracy or loss.  \n",
        "\n",
        "\n",
        "\n",
        "### **üìå Note:**\n",
        "All the labs will follow this structure. You will just modify the content for different tasks, such as changing datasets, architectures, or loss functions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXG9aSXCYaza"
      },
      "source": [
        "## 1Ô∏è‚É£ **Dataset Class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOwm0-zsulwK"
      },
      "source": [
        "In PyTorch, a **Dataset Class** is responsible for transforming raw data into samples that are ready to be used by a model.  \n",
        "Each sample returned consists of:\n",
        "- An **input** (features or image)\n",
        "- Its corresponding **label**  \n",
        "\n",
        "\n",
        "\n",
        "## üîπ For Tabular Data (Using `TensorDataset`)\n",
        "\n",
        "When working with **tabular data** (e.g., CSV files already converted to tensors), we can use\n",
        "`TensorDataset` to pair input features with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNlgbwZPnD6H",
        "outputId": "31a40ee2-2bfa-47e2-bfd7-86e35db4cd4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "tensor([-1.0720e+00, -6.5842e-01, -1.0881e+00, -9.3927e-01, -1.3594e-01,\n",
            "        -1.0087e+00, -9.6836e-01, -1.1020e+00,  2.8106e-01, -1.1323e-01,\n",
            "        -7.0486e-01, -4.4094e-01, -7.4395e-01, -6.2980e-01,  7.4806e-04,\n",
            "        -9.9157e-01, -6.9376e-01, -9.8328e-01, -5.9158e-01, -4.2897e-01,\n",
            "        -1.0341e+00, -6.2350e-01, -1.0708e+00, -8.7653e-01, -1.6998e-01,\n",
            "        -1.0388e+00, -1.0790e+00, -1.3505e+00, -3.5266e-01, -5.4138e-01])\n",
            "tensor(1.)\n",
            "Shape of one sample: torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "print(X.shape)\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# TensorDataset pairs input features (X) with their corresponding labels (y)\n",
        "# Each item in the dataset is returned as (X[i], y[i])\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Access a single sample from the dataset\n",
        "# This helps verify the shape of one data sample\n",
        "first_sample, first_label = train_dataset[0]\n",
        "print(first_sample)\n",
        "print(first_label)\n",
        "print(f\"Shape of one sample: {first_sample.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMPiHVpcxYt5"
      },
      "source": [
        "## üîπ For Image Data (Using Built-in Datasets)\n",
        "\n",
        "In PyTorch, image datasets can be:\n",
        "- **Built-in datasets** provided by PyTorch (e.g., MNIST, CIFAR-10)\n",
        "- **Custom datasets** created for data that is not provided in a ready-made format\n",
        "\n",
        "In **Stage 2**, we'll use **built-in datasets**\n",
        "\n",
        "In **Stage 3**, we'll create **custom Dataset classes** for our own image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCinzfXNyUON",
        "outputId": "5981bd81-66c1-402f-d7d1-93bf8a9755bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 107MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 49.4MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 74.1MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 10.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Image shape: torch.Size([1, 28, 28])\n",
            "Label: 5\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=True,            # Use training data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# Testing dataset\n",
        "test_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=False,           # Use test data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# print one sample from the dataset\n",
        "# Each sample consists of an image tensor and its label\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "print(f\"\\n Image shape: {sample_image.shape}\")  # (1, 28, 28)\n",
        "print(f\"Label: {sample_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5WZp8HJ6fK"
      },
      "source": [
        "\n",
        "Right now, our **Dataset Class** loads **one sample at a time** when we call:\n",
        "```python\n",
        "sample_image, sample_label = train_dataset[0]  # Loads only one sample\n",
        "```\n",
        "‚úÖ **That‚Äôs great for understanding**, but when training a model, we need to process **multiple samples at once** for efficiency.\n",
        "\n",
        "‚ùå **Problem**: We need batches, not single samples.  \n",
        "‚úÖ **Solution**: We use `DataLoader` to handle batching automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CEW3kknM6t3"
      },
      "source": [
        "## üìå **What are DataLoaders ?**\n",
        "\n",
        "<img src=\"https://i.imgur.com/aHE3lnE.png\" width=\"70%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GKnrdjFPtH"
      },
      "source": [
        "\n",
        "A **DataLoader** is a PyTorch utility that takes a Dataset and does:\n",
        "- **Batching**: Groups multiple samples together for faster processing.\n",
        "- **Shuffling**: Randomizes data order to improve training.\n",
        "- **Multi-threading**: Loads data efficiently in parallel.\n",
        "\n",
        "| **Argument**     | **Description** |\n",
        "|-----------------|---------------|\n",
        "| `dataset` | The dataset object (e.g., `train_dataset`) |\n",
        "| `batch_size` | Number of samples per batch (e.g., `32`) |\n",
        "| `shuffle` | Whether to **randomly shuffle** data each epoch (`True` = better for training) |\n",
        "| `num_workers` | Number of parallel **CPU workers** to load data faster |\n",
        "| `collate_fn` | A function to **customize how data is stacked** (useful when data has variable sizes) |\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qivcbu_CNXfh",
        "outputId": "40b2e732-3f27-48de-b0e1-a0dbe0f1406c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch input shape: torch.Size([32, 1, 28, 28])\n",
            "Training batch labels shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader for training data\n",
        "train_loader = DataLoader( #very importent\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "# DataLoader for test/validation data\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,#bcs i don't want to see the performance in testing only in validaition\n",
        "    num_workers=2\n",
        ")\n",
        "# Get the first batch from the training DataLoader\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f\"Training batch input shape: {X_batch.shape}\")\n",
        "print(f\"Training batch labels shape: {y_batch.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKlCp-MvZVt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU57FGt_Ykoj"
      },
      "source": [
        "## 2Ô∏è‚É£ **Model Class**\n",
        "\n",
        "In PyTorch, `nn.Linear(in_features, out_features)`\n",
        "\n",
        "creates a **fully connected (dense) layer** that applies a linear transformation:\n",
        "\n",
        "$y = xW^T + b$\n",
        "\n",
        "\n",
        "- **`in_features`**: number of input features  \n",
        "- **`out_features`**: number of neurons (outputs) in the layer  \n",
        "- The layer automatically creates learnable **weights** and **bias**.\n",
        "\n",
        "‚úÖ Example: a layer that takes 3 input features and outputs 1 value:\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42PESt1sUw0",
        "outputId": "6429edbb-a95e-41cf-f66e-512bb864912a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 3])\n",
            "Output shape: torch.Size([4, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a linear layer: 3 input features -> 1 output\n",
        "linear = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "# Example input: batch of 4 samples, each with 3 features\n",
        "x = torch.randn(4, 3)\n",
        "\n",
        "# Forward through the layer\n",
        "y = linear(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)   # torch.Size([4, 3])\n",
        "print(\"Output shape:\", y.shape)  # torch.Size([4, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNCHp3ihvl6s"
      },
      "source": [
        "### **üìå Key Components of Model Class:**\n",
        "####1Ô∏è‚É£ **Define Layers (`__init__` method):**  \n",
        "\n",
        "Inside the `__init__` method, we define **what the neural network looks like**. This includes:\n",
        "\n",
        "- **Number of layers**  \n",
        "  How many linear (`nn.Linear`) layers the model has (depth of the network).\n",
        "\n",
        "- **Hidden layer sizes**  \n",
        "  How many neurons each hidden layer contains.\n",
        "\n",
        "- **Activation functions**  \n",
        "  Activation functions introduce **non-linearity**, allowing the network to learn complex patterns.\n",
        "  - Common choice for hidden layers: **ReLU**\n",
        "\n",
        "- **Output activation function**  \n",
        "  The activation used at the final layer depends on the task:\n",
        "  - **Binary classification** ‚Üí `Sigmoid`\n",
        "  - **Multiclass classification** ‚Üí `Softmax`\n",
        "  - **Regression** ‚Üí No activation (linear output)\n",
        "\n",
        "üìå **Important:**  \n",
        "Hidden layers usually use ReLU, while the **output layer activation is task-dependent**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfyCtXWsTgF"
      },
      "source": [
        "#### 2Ô∏è‚É£ **Forward Pass (`forward` method):**\n",
        "\n",
        "The `forward()` method defines **how the input data flows through the model** to produce the final output.\n",
        "\n",
        "- The input tensor is passed through each layer **in order**.\n",
        "- Activation functions are applied after linear layers to introduce **non-linearity**.\n",
        "- The final layer produces the model‚Äôs prediction.\n",
        "\n",
        "üìå **Note:**  \n",
        "During training, PyTorch automatically tracks all operations in the `forward()` method to compute gradients during backpropagation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6qfrKJK88F"
      },
      "source": [
        "‚úÖ **Example: One neural network layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmUbfIKiZc8X"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IAkZWzDOYGaiu3e47rEMgQ.png\" width=\"60%\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Opi3_J4dE_pT"
      },
      "outputs": [],
      "source": [
        "class NN1Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "\n",
        "    super(NN1Layer, self).__init__()\n",
        "    # input_dim = num of features, Output for binary classification is 1\n",
        "    self.layer_1 = nn.Linear(input_dim, 1)\n",
        "\n",
        "    # output activation function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, x):\n",
        "    z = self.layer_1(x)\n",
        "    a = self.sigmoid(z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLXie4eWLSjd"
      },
      "source": [
        "‚úÖ **Example: Two neural network layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLPIVOoIhOhv"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/0*GZrkL6Lqt9dIAJ61.jpg\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "87V4-6vDFxlM"
      },
      "outputs": [],
      "source": [
        "class NN2Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "\n",
        "        super(NN2Layer, self).__init__()\n",
        "        # input_dim = num of features, hidden_dim = num of neurons\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # hidden_dim = num of neurons, Output for binary classification is 1\n",
        "        self.layer2 = nn.Linear(hidden_dim, 1)#weight is initilais inside in method\n",
        "\n",
        "        # non-linearity activation function\n",
        "        self.relu = nn.ReLU()\n",
        "        # output activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, x):\n",
        "        z1 = self.layer1(x)\n",
        "        a1 = self.relu(z1)\n",
        "        z2 = self.layer2(a1)\n",
        "        a2 = self.sigmoid(z2)\n",
        "        return a2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEZs4vBe1dJ"
      },
      "source": [
        "\n",
        "\n",
        "> We can instantiate the model and print it to see the architecture, layers, and total number of trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKrJiWQTdgYZ",
        "outputId": "b7b7ead5-c4ac-4e9a-ddca-11e4360cc6d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "\n",
            "NN2Layer(\n",
            "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (layer2): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Total trainable parameters: 19\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model\n",
        "input_dim = 4     # number of input features\n",
        "hidden_dim = 3    # number of hidden neurons\n",
        "\n",
        "model = NN2Layer(input_dim, hidden_dim)\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"Model Architecture:\\n\")\n",
        "print(model)\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYO9UOyvWYR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o42xnLsEYr8D"
      },
      "source": [
        "## 3Ô∏è‚É£ **Training Loop**\n",
        "\n",
        "The **training loop** is responsible for **updating the model's weights** so that it learns to minimize the loss function.\n",
        "\n",
        "### üß© **Parameters**\n",
        "\n",
        "- **`model`** ‚Äì The neural network to be trained.  \n",
        "- **`optimizer`** ‚Äì Updates model parameters (e.g., SGD, Adam).  \n",
        "- **`criterion`** ‚Äì Loss function, depends on the task.  \n",
        "- **`train_loader`** ‚Äì PyTorch `DataLoader` that provides batches of training data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hfanJzrdnFA_"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to the selected device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass & optimization\n",
        "        optimizer.zero_grad()   # Clear previous gradients\n",
        "        loss.backward()         # Compute gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Average loss over all batches\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYUwAxlpXzY"
      },
      "source": [
        "###üìå **For criterions (Loss Functions)**:\n",
        "Different tasks require different loss functions\n",
        "- Linear Regression ‚Üí `nn.MSELoss()`  \n",
        "- Binary classification ‚Üí `nn.BCELoss()`  \n",
        "- Multiclass classification ‚Üí `nn.CrossEntropyLoss()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYXDDeNqwCY"
      },
      "source": [
        "####1Ô∏è‚É£ `nn.MSELoss()`\n",
        "- `MSELoss` expects **continuous values** (regression).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDWNgCK2sCDo",
        "outputId": "463666c1-52eb-447f-8c17-43c77279e42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss: 0.25\n"
          ]
        }
      ],
      "source": [
        "# Example predictions and targets\n",
        "y_pred = torch.tensor([[2.5], [3.0], [4.5]])\n",
        "y_true = torch.tensor([[3.0], [2.5], [5.0]])\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"MSE Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9OMs--Rs4Jk"
      },
      "source": [
        "####2Ô∏è‚É£ `nn.BCELoss()`\n",
        "- `BCELoss` expects **probabilities** between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lNu1qss7rz",
        "outputId": "2f34f63c-831c-4d60-e7ab-117911026056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross Entropy Loss: 0.36354804039001465\n"
          ]
        }
      ],
      "source": [
        "# Predicted probabilities (after sigmoid)\n",
        "y_pred = torch.tensor([[0.8], [0.3], [0.6]])\n",
        "y_true = torch.tensor([[1.0], [0.0], [1.0]])\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"Binary Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8bgGs6tFJi"
      },
      "source": [
        "####3Ô∏è‚É£ `nn.CrossEntropyLoss()`\n",
        "- `CrossEntropyLoss` expects **raw logits** (no Softmax needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaba4iKbta-I",
        "outputId": "6882d7cf-4af4-47c0-c8b4-697198abe361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss: 0.450598806142807\n"
          ]
        }
      ],
      "source": [
        "# Raw model outputs (logits), shape: (batch_size, num_classes)\n",
        "logits = torch.tensor([\n",
        "    [2.0, 0.5, 1.0],\n",
        "    [0.1, 1.5, 0.3]\n",
        "])\n",
        "# True class indices\n",
        "targets = torch.tensor([0, 1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(logits, targets)\n",
        "print(\"Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlJgjmKvjbp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Isn-l9gYyfT"
      },
      "source": [
        "\n",
        "## 4Ô∏è‚É£ **Validation Loop**\n",
        "\n",
        "The **validation loop** evaluates the model‚Äôs performance on unseen data **without updating the weights**.\n",
        "\n",
        "It is used to measure how well the model generalizes.\n",
        "\n",
        "### üß© Parameters\n",
        "\n",
        "- **`model`** ‚Äì The trained neural network to be evaluated.  \n",
        "- **`criterion`** ‚Äì Loss function used for evaluation\n",
        "- **`test_loader`** ‚Äì PyTorch `DataLoader` that provides batches of validation/test data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).  \n",
        "\n",
        "\n",
        "üìå **Note:**  \n",
        "Gradients are disabled during validation using `torch.no_grad()` to improve efficiency and prevent weight updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pxMyr159d5UW"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, test_loader, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            # Move batch to the selected device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Binary predictions\n",
        "            predicted = (outputs > 0.5).float()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bcKsHoLvTxk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoj068knVPN"
      },
      "source": [
        "## **üìå Full Training Process in PyTorch**\n",
        "\n",
        "Now that you understand the **Dataset Class, Model Class, Training Loop, and Validation Loop**, it's time to put everything together into a **full training process**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUK2taqBkUyR"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zryj9VCzkaHl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOguR6wwkmlr"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BT-TaJLL6isg"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets for training and testing\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create Dataloaders to train and test data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Y-oPSxlJOw"
      },
      "source": [
        "### Run full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgTf7gdlOQZ",
        "outputId": "a391a4ed-d40b-47c8-c130-c1f7d9454613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Starting Training...\n",
            "Epoch [5/50], Train Loss: 0.4161, Val Loss: 0.4015, Val Accuracy: 0.8860\n",
            "Epoch [10/50], Train Loss: 0.1972, Val Loss: 0.2244, Val Accuracy: 0.9561\n",
            "Epoch [15/50], Train Loss: 0.1276, Val Loss: 0.1601, Val Accuracy: 0.9561\n",
            "Epoch [20/50], Train Loss: 0.0975, Val Loss: 0.1298, Val Accuracy: 0.9561\n",
            "Epoch [25/50], Train Loss: 0.0807, Val Loss: 0.1139, Val Accuracy: 0.9649\n",
            "Epoch [30/50], Train Loss: 0.0715, Val Loss: 0.1028, Val Accuracy: 0.9649\n",
            "Epoch [35/50], Train Loss: 0.0642, Val Loss: 0.0953, Val Accuracy: 0.9649\n",
            "Epoch [40/50], Train Loss: 0.0614, Val Loss: 0.0901, Val Accuracy: 0.9649\n",
            "Epoch [45/50], Train Loss: 0.0547, Val Loss: 0.0867, Val Accuracy: 0.9649\n",
            "Epoch [50/50], Train Loss: 0.0528, Val Loss: 0.0841, Val Accuracy: 0.9649\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model, Criterion, Optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 10\n",
        "model =NN2Layer(input_dim, hidden_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Run Training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print('Starting Training...')\n",
        "for epoch in range(num_epochs):\n",
        "    # Train one epoch\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_accuracy = validate(model, criterion, test_loader, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvMxHD4nfTs"
      },
      "source": [
        "### Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1ftDlPPhniA6",
        "outputId": "aa34f568-2fec-49c7-8569-a95efbea5ffe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting results\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvSQimxq_3O"
      },
      "source": [
        "## Now you know how to use PyTorch for NNs :)\n",
        "\n",
        "\n",
        "![image.png](https://i.imgur.com/1xbDOQX.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDl5V6-7SOal"
      },
      "source": [
        "### **Contributed by: Yara Alzahrani, Mohamed Eltayeb**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}