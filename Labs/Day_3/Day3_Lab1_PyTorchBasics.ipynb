{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KamP67nRt-Ko"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRn1N6ZuHHg"
      },
      "source": [
        "#**Lab: Pytorch Basics**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZXwf7gKK_Ia"
      },
      "source": [
        "## **What is Pytorch?** <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/PyTorch_logo_icon.svg/500px-PyTorch_logo_icon.svg.png\" width=\"4%\">\n",
        "\n",
        "\n",
        "**PyTorch** is an open-source deep learning framework that allows us to build and train neural networks using **tensors** and **automatic differentiation**.  \n",
        "It provides simple, flexible tools to define models, compute gradients using backpropagation, and optimize parameters efficiently.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMLes6srWwMe"
      },
      "source": [
        "## üì¶ **Tensors in PyTorch**\n",
        "\n",
        "A **tensor** is the main data structure in PyTorch.  \n",
        "It is similar to a NumPy array, but can run on both CPUs and GPUs.\n",
        "\n",
        "Tensors are used to represent: input data, model parameters, and model outputs\n",
        "\n",
        "### üîπ Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_R5-1UJaw0w",
        "outputId": "bee1bcfe-3abf-4f20-916d-601f7706c09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([1., 2., 3.])\n",
            "y: tensor([-0.1696, -0.7806,  0.5588])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.randn(3)\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1boO-_nua7dB"
      },
      "source": [
        "### üîπ Tensor Shapes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDn9esxa_o_",
        "outputId": "a8c94626-a5f7-410a-eb0a-8c0ceccefa8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x:\", x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfrk3ELobLIP"
      },
      "source": [
        "### üîπ Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Krsxjc3bYqo",
        "outputId": "fd57c70e-c785-4676-9ef7-c86751665658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: tensor([5., 7., 9.])\n",
            "Multiplication: tensor([ 4., 10., 18.])\n",
            "Matrix multiplication result shape: torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "# Element-wise operations\n",
        "print(\"Addition:\", a + b)\n",
        "print(\"Multiplication:\", a * b)\n",
        "\n",
        "# Matrix multiplication\n",
        "A = torch.randn(2, 3)\n",
        "B = torch.randn(3, 2)\n",
        "C = A @ B\n",
        "\n",
        "print(\"Matrix multiplication result shape:\", C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rYObkabicO"
      },
      "source": [
        "\n",
        "\n",
        "> See! just like Numpy Arrays, but more powerful!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOtVHO3WY_-"
      },
      "source": [
        "---\n",
        "## üìä **Data Representation in Deep Learning**\n",
        "\n",
        "The way data is represented depends on whether it is **structured (tabular)** or **unstructured (images)**.\n",
        "\n",
        "### üîπ1Ô∏è‚É£ **Tabular Data (Structured Data)**\n",
        "Tabular data consists of rows and columns.\n",
        "\n",
        "Each row represents a sample and each column represents a feature.\n",
        "\n",
        "- Represented as a **2D tensor**\n",
        "- Shape: `(batch_size, number_of_features)`\n",
        "- Commonly used for tasks like regression and classification\n",
        "\n",
        "Example:\n",
        "- Features: age, salary, debt  \n",
        "- Tensor shape: `(N, 3)`\n",
        "\n",
        "### üîπ2Ô∏è‚É£ **Image Data (Unstructured Data)**\n",
        "Image data is unstructured and contains spatial information.\n",
        "\n",
        "- Represented as a **4D tensor**\n",
        "- Shape: `(batch_size, channels, height, width)`\n",
        "- Channels represent color information:\n",
        "  - Grayscale ‚Üí 1 channel\n",
        "  - RGB ‚Üí 3 channels\n",
        "\n",
        "Example:\n",
        "- RGB image of size 224√ó224  \n",
        "- Tensor shape: `(N, 3, 224, 224)`\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27NITm3aWla9"
      },
      "source": [
        "## üìå **How to Change Dimensions in PyTorch?**\n",
        "\n",
        "Manipulating tensor shapes is essential in deep learning. PyTorch provides several functions to modify tensor dimensions.\n",
        "\n",
        "### **üîπ 1Ô∏è‚É£ Flatten**\n",
        "- Converts **any shape** to `(batch_size, features)`.\n",
        "- **Example:**  \n",
        "  `(batch_size, channels, height, width) ‚Üí (batch_size, features)`\n",
        "\n",
        "### **üîπ 2Ô∏è‚É£ Squeeze**\n",
        "- **Removes dimensions** with size `1`.\n",
        "- **Example:**  \n",
        "  `(1, 32, 3, 28, 28) ‚Üí (32, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 3Ô∏è‚É£ Unsqueeze**\n",
        "- **Adds a dimension** with size `1` at a specified position.\n",
        "- **Example:**  \n",
        "  `(3, 28, 28) ‚Üí (1, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 4Ô∏è‚É£ View (works similar to reshape)**\n",
        "- **Reshapes a tensor freely** while maintaining the same number of elements.\n",
        "- **Example:**  \n",
        "  `(32, 3, 28, 28) ‚Üí view(-1, 3*28*28) ‚Üí (32, 3*28*28)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY0z_-JwRYWk",
        "outputId": "8a690172-cb68-454e-b7b7-ec47f3a2f397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flatten: torch.Size([32, 2352])\n",
            "Squeeze: torch.Size([3, 28, 28])\n",
            "Unsqueeze: torch.Size([1, 3, 28, 28])\n",
            "View: torch.Size([32, 2352])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1Ô∏è‚É£ Flatten - Convert any shape to (batch_size, features)\n",
        "# convert from 4d to 2d\n",
        "x = torch.randn(32, 3, 28, 28) #(num of sample, rdg,h,w)\n",
        "x_flat = x.flatten(start_dim=1)# with out thing in () well multi all dim to gather\n",
        "print(\"Flatten:\", x_flat.shape)  # (32, 2352) row and column\n",
        "\n",
        "# 2Ô∏è‚É£ Squeeze - Remove dimensions with size 1\n",
        "x = torch.randn(1, 3, 28, 28)\n",
        "x_sq = x.squeeze()\n",
        "print(\"Squeeze:\", x_sq.shape)  # (3, 28, 28)\n",
        "\n",
        "# 3Ô∏è‚É£ Unsqueeze - Add a new dimension of size 1\n",
        "x = torch.randn(3, 28, 28)\n",
        "x_unsq = x.unsqueeze(0) #add to first posision\n",
        "print(\"Unsqueeze:\", x_unsq.shape)  # (1, 3, 28, 28)\n",
        "\n",
        "# 4Ô∏è‚É£ View - Reshape freely while keeping same number of elements\n",
        "x = torch.randn(32, 28, 28, 3)\n",
        "x_view = x.view(32, -1)  # Flatten all except batch\n",
        "print(\"View:\", x_view.shape)  # (32, 28*28*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q98MVwNxvNwL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrCEfnNborH"
      },
      "source": [
        "## üìå **Changing Data Type or Moving Data/Model to CPU/GPU**  \n",
        "\n",
        "PyTorch allows you to **change the datatype** of a tensor and **move it between CPU and GPU** using `.to()`.  \n",
        "\n",
        "\n",
        "### üîπ **Change Datatype**\n",
        "Use `.to(dtype)` to convert a tensor's data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAQnY7HWYlG",
        "outputId": "d0b6f558-eafe-44e4-ce77-02ad980194a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a float32 tensor\n",
        "x = torch.tensor([1.2, 2.3, 3.4], dtype=torch.float32)\n",
        "print(x.dtype)  # Output: torch.float32\n",
        "\n",
        "# Convert to float16\n",
        "x_half = x.to(torch.float16)\n",
        "print(x_half.dtype)  # Output: torch.float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MOJ8tx0ceVL"
      },
      "source": [
        "### üîπ **Move Tensors to GPU (if available)**\n",
        "**GPUs are faster and more efficient** in most cases when training or inferencing deep learning models.\n",
        "\n",
        "Use `.to(device)` to move a tensor to GPU for faster computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iv00vultxnB",
        "outputId": "f2240e0d-5385-4c20-8338-a517c1d88d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Automatically select CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create a tensor and move it to GPU\n",
        "x_gpu = x.to(device)\n",
        "print(x_gpu.device)  # Output: cuda:0 (if GPU is available) or cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEVOLXed3ut"
      },
      "source": [
        "Note: When training a model, always move BOTH the model and data to the same device. Otherwise, you will get an error like this:\n",
        "\n",
        "`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8DN_nVlUbod"
      },
      "source": [
        "## **üìå PyTorch Workflow Organization**\n",
        "\n",
        "### **It consists of 4 main components:**\n",
        "1Ô∏è‚É£ **Dataset Class**  \n",
        "- Handles loading and preprocessing data.  \n",
        "- Converts raw data (e.g., images, CSVs) into model-ready tensors.  \n",
        "\n",
        "2Ô∏è‚É£ **Model Class**  \n",
        "- Defines the architecture of your neural network (e.g., layers, activations).  \n",
        "\n",
        "3Ô∏è‚É£ **Training Loop**  \n",
        "- Updates model weights using backpropagation and optimizers.  \n",
        "- Computes the loss for every batch and adjusts the parameters to minimize it.  \n",
        "\n",
        "4Ô∏è‚É£ **Validation Loop**  \n",
        "- Evaluates the model's performance on a validation set.  \n",
        "- Does not update weights but computes metrics like accuracy or loss.  \n",
        "\n",
        "\n",
        "\n",
        "### **üìå Note:**\n",
        "All the labs will follow this structure. You will just modify the content for different tasks, such as changing datasets, architectures, or loss functions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXG9aSXCYaza"
      },
      "source": [
        "## 1Ô∏è‚É£ **Dataset Class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOwm0-zsulwK"
      },
      "source": [
        "In PyTorch, a **Dataset Class** is responsible for transforming raw data into samples that are ready to be used by a model.  \n",
        "Each sample returned consists of:\n",
        "- An **input** (features or image)\n",
        "- Its corresponding **label**  \n",
        "\n",
        "\n",
        "\n",
        "## üîπ For Tabular Data (Using `TensorDataset`)\n",
        "\n",
        "When working with **tabular data** (e.g., CSV files already converted to tensors), we can use\n",
        "`TensorDataset` to pair input features with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNlgbwZPnD6H",
        "outputId": "3bc7eb96-1047-4c71-e656-be70d8ee0e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one sample: torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# TensorDataset pairs input features (X) with their corresponding labels (y)\n",
        "# Each item in the dataset is returned as (X[i], y[i])\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Access a single sample from the dataset\n",
        "# This helps verify the shape of one data sample\n",
        "first_sample, _ = train_dataset[0]\n",
        "print(f\"Shape of one sample: {first_sample.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMPiHVpcxYt5"
      },
      "source": [
        "## üîπ For Image Data (Using Built-in Datasets)\n",
        "\n",
        "In PyTorch, image datasets can be:\n",
        "- **Built-in datasets** provided by PyTorch (e.g., MNIST, CIFAR-10)\n",
        "- **Custom datasets** created for data that is not provided in a ready-made format\n",
        "\n",
        "In **Stage 2**, we'll use **built-in datasets**\n",
        "\n",
        "In **Stage 3**, we'll create **custom Dataset classes** for our own image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCinzfXNyUON",
        "outputId": "d0176054-76df-469b-9bf5-8f6c4a4fa4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 483kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 8.42MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Image shape: torch.Size([1, 28, 28])\n",
            "Label: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=True,            # Use training data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# Testing dataset\n",
        "test_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=False,           # Use test data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# print one sample from the dataset\n",
        "# Each sample consists of an image tensor and its label\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "print(f\"\\n Image shape: {sample_image.shape}\")  # (1, 28, 28)\n",
        "print(f\"Label: {sample_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5WZp8HJ6fK"
      },
      "source": [
        "\n",
        "Right now, our **Dataset Class** loads **one sample at a time** when we call:\n",
        "```python\n",
        "sample_image, sample_label = train_dataset[0]  # Loads only one sample\n",
        "```\n",
        "‚úÖ **That‚Äôs great for understanding**, but when training a model, we need to process **multiple samples at once** for efficiency.\n",
        "\n",
        "‚ùå **Problem**: We need batches, not single samples.  \n",
        "‚úÖ **Solution**: We use `DataLoader` to handle batching automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CEW3kknM6t3"
      },
      "source": [
        "## üìå **What are DataLoaders ?**\n",
        "\n",
        "<img src=\"https://i.imgur.com/aHE3lnE.png\" width=\"70%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GKnrdjFPtH"
      },
      "source": [
        "\n",
        "A **DataLoader** is a PyTorch utility that takes a Dataset and does:\n",
        "- **Batching**: Groups multiple samples together for faster processing.\n",
        "- **Shuffling**: Randomizes data order to improve training.\n",
        "- **Multi-threading**: Loads data efficiently in parallel.\n",
        "\n",
        "| **Argument**     | **Description** |\n",
        "|-----------------|---------------|\n",
        "| `dataset` | The dataset object (e.g., `train_dataset`) |\n",
        "| `batch_size` | Number of samples per batch (e.g., `32`) |\n",
        "| `shuffle` | Whether to **randomly shuffle** data each epoch (`True` = better for training) |\n",
        "| `num_workers` | Number of parallel **CPU workers** to load data faster |\n",
        "| `collate_fn` | A function to **customize how data is stacked** (useful when data has variable sizes) |\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qivcbu_CNXfh",
        "outputId": "cb24261a-bd36-4c41-c7d2-7cdc014da307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training batch input shape: torch.Size([32, 1, 28, 28])\n",
            "Training batch labels shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader for training data\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "# DataLoader for test/validation data\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "# Get the first batch from the training DataLoader\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f\"Training batch input shape: {X_batch.shape}\")\n",
        "print(f\"Training batch labels shape: {y_batch.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKlCp-MvZVt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU57FGt_Ykoj"
      },
      "source": [
        "## 2Ô∏è‚É£ **Model Class**\n",
        "\n",
        "In PyTorch, `nn.Linear(in_features, out_features)`\n",
        "\n",
        "creates a **fully connected (dense) layer** that applies a linear transformation:\n",
        "\n",
        "$y = xW^T + b$\n",
        "\n",
        "\n",
        "- **`in_features`**: number of input features  \n",
        "- **`out_features`**: number of neurons (outputs) in the layer  \n",
        "- The layer automatically creates learnable **weights** and **bias**.\n",
        "\n",
        "‚úÖ Example: a layer that takes 3 input features and outputs 1 value:\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42PESt1sUw0",
        "outputId": "f6bb97e0-fc3c-4484-a268-237b8816971d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 3])\n",
            "Output shape: torch.Size([4, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a linear layer: 3 input features -> 1 output\n",
        "linear = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "# Example input: batch of 4 samples, each with 3 features\n",
        "x = torch.randn(4, 3)\n",
        "\n",
        "# Forward through the layer\n",
        "y = linear(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)   # torch.Size([4, 3])\n",
        "print(\"Output shape:\", y.shape)  # torch.Size([4, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNCHp3ihvl6s"
      },
      "source": [
        "### **üìå Key Components of Model Class:**\n",
        "####1Ô∏è‚É£ **Define Layers (`__init__` method):**  \n",
        "\n",
        "Inside the `__init__` method, we define **what the neural network looks like**. This includes:\n",
        "\n",
        "- **Number of layers**  \n",
        "  How many linear (`nn.Linear`) layers the model has (depth of the network).\n",
        "\n",
        "- **Hidden layer sizes**  \n",
        "  How many neurons each hidden layer contains.\n",
        "\n",
        "- **Activation functions**  \n",
        "  Activation functions introduce **non-linearity**, allowing the network to learn complex patterns.\n",
        "  - Common choice for hidden layers: **ReLU**\n",
        "\n",
        "- **Output activation function**  \n",
        "  The activation used at the final layer depends on the task:\n",
        "  - **Binary classification** ‚Üí `Sigmoid`\n",
        "  - **Multiclass classification** ‚Üí `Softmax`\n",
        "  - **Regression** ‚Üí No activation (linear output)\n",
        "\n",
        "üìå **Important:**  \n",
        "Hidden layers usually use ReLU, while the **output layer activation is task-dependent**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfyCtXWsTgF"
      },
      "source": [
        "#### 2Ô∏è‚É£ **Forward Pass (`forward` method):**\n",
        "\n",
        "The `forward()` method defines **how the input data flows through the model** to produce the final output.\n",
        "\n",
        "- The input tensor is passed through each layer **in order**.\n",
        "- Activation functions are applied after linear layers to introduce **non-linearity**.\n",
        "- The final layer produces the model‚Äôs prediction.\n",
        "\n",
        "üìå **Note:**  \n",
        "During training, PyTorch automatically tracks all operations in the `forward()` method to compute gradients during backpropagation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6qfrKJK88F"
      },
      "source": [
        "‚úÖ **Example: One neural network layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmUbfIKiZc8X"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IAkZWzDOYGaiu3e47rEMgQ.png\" width=\"60%\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Opi3_J4dE_pT"
      },
      "outputs": [],
      "source": [
        "class NN1Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "\n",
        "    super(NN1Layer, self).__init__()\n",
        "    # input_dim = num of features, Output for binary classification is 1\n",
        "    self.layer_1 = nn.Linear(input_dim, 1)\n",
        "\n",
        "    # output activation function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, x):\n",
        "    z = self.layer_1(x)\n",
        "    a = self.sigmoid(z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLXie4eWLSjd"
      },
      "source": [
        "‚úÖ **Example: Two neural network layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLPIVOoIhOhv"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/0*GZrkL6Lqt9dIAJ61.jpg\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "87V4-6vDFxlM"
      },
      "outputs": [],
      "source": [
        "class NN2Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "\n",
        "        super(NN2Layer, self).__init__()\n",
        "        # input_dim = num of features, hidden_dim = num of neurons\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # hidden_dim = num of neurons, Output for binary classification is 1\n",
        "        self.layer2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        # non-linearity activation function\n",
        "        self.relu = nn.ReLU()\n",
        "        # output activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, x):\n",
        "        z1 = self.layer1(x)\n",
        "        a1 = self.relu(z1)\n",
        "        z2 = self.layer2(a1)\n",
        "        a2 = self.sigmoid(z2)\n",
        "        return a2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEZs4vBe1dJ"
      },
      "source": [
        "\n",
        "\n",
        "> We can instantiate the model and print it to see the architecture, layers, and total number of trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKrJiWQTdgYZ",
        "outputId": "6703b3ab-a5ed-471a-f5b1-6e0f9b67ae6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "\n",
            "NN2Layer(\n",
            "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (layer2): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Total trainable parameters: 19\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model\n",
        "input_dim = 4     # number of input features\n",
        "hidden_dim = 3    # number of hidden neurons\n",
        "\n",
        "model = NN2Layer(input_dim, hidden_dim)\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"Model Architecture:\\n\")\n",
        "print(model)\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYO9UOyvWYR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o42xnLsEYr8D"
      },
      "source": [
        "## 3Ô∏è‚É£ **Training Loop**\n",
        "\n",
        "The **training loop** is responsible for **updating the model's weights** so that it learns to minimize the loss function.\n",
        "\n",
        "### üß© **Parameters**\n",
        "\n",
        "- **`model`** ‚Äì The neural network to be trained.  \n",
        "- **`optimizer`** ‚Äì Updates model parameters (e.g., SGD, Adam).  \n",
        "- **`criterion`** ‚Äì Loss function, depends on the task.  \n",
        "- **`train_loader`** ‚Äì PyTorch `DataLoader` that provides batches of training data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hfanJzrdnFA_"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to the selected device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass & optimization\n",
        "        optimizer.zero_grad()   # Clear previous gradients\n",
        "        loss.backward()         # Compute gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Average loss over all batches\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYUwAxlpXzY"
      },
      "source": [
        "###üìå **For criterions (Loss Functions)**:\n",
        "Different tasks require different loss functions\n",
        "- Linear Regression ‚Üí `nn.MSELoss()`  \n",
        "- Binary classification ‚Üí `nn.BCELoss()`  \n",
        "- Multiclass classification ‚Üí `nn.CrossEntropyLoss()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYXDDeNqwCY"
      },
      "source": [
        "####1Ô∏è‚É£ `nn.MSELoss()`\n",
        "- `MSELoss` expects **continuous values** (regression).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDWNgCK2sCDo",
        "outputId": "01200126-86f7-45ab-fe16-0850814da947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss: 0.25\n"
          ]
        }
      ],
      "source": [
        "# Example predictions and targets\n",
        "y_pred = torch.tensor([[2.5], [3.0], [4.5]])\n",
        "y_true = torch.tensor([[3.0], [2.5], [5.0]])\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"MSE Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9OMs--Rs4Jk"
      },
      "source": [
        "####2Ô∏è‚É£ `nn.BCELoss()`\n",
        "- `BCELoss` expects **probabilities** between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lNu1qss7rz",
        "outputId": "7621ad7a-d5bc-4c6f-efb7-b1ed1b895afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross Entropy Loss: 0.36354804039001465\n"
          ]
        }
      ],
      "source": [
        "# Predicted probabilities (after sigmoid)\n",
        "y_pred = torch.tensor([[0.8], [0.3], [0.6]])\n",
        "y_true = torch.tensor([[1.0], [0.0], [1.0]])\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"Binary Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8bgGs6tFJi"
      },
      "source": [
        "####3Ô∏è‚É£ `nn.CrossEntropyLoss()`\n",
        "- `CrossEntropyLoss` expects **raw logits** (no Softmax needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaba4iKbta-I",
        "outputId": "b5323f3e-04ca-4642-d723-679d0993a2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss: 0.450598806142807\n"
          ]
        }
      ],
      "source": [
        "# Raw model outputs (logits), shape: (batch_size, num_classes)\n",
        "logits = torch.tensor([\n",
        "    [2.0, 0.5, 1.0],\n",
        "    [0.1, 1.5, 0.3]\n",
        "])\n",
        "# True class indices\n",
        "targets = torch.tensor([0, 1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(logits, targets)\n",
        "print(\"Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlJgjmKvjbp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Isn-l9gYyfT"
      },
      "source": [
        "\n",
        "## 4Ô∏è‚É£ **Validation Loop**\n",
        "\n",
        "The **validation loop** evaluates the model‚Äôs performance on unseen data **without updating the weights**.\n",
        "\n",
        "It is used to measure how well the model generalizes.\n",
        "\n",
        "### üß© Parameters\n",
        "\n",
        "- **`model`** ‚Äì The trained neural network to be evaluated.  \n",
        "- **`criterion`** ‚Äì Loss function used for evaluation\n",
        "- **`test_loader`** ‚Äì PyTorch `DataLoader` that provides batches of validation/test data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).  \n",
        "\n",
        "\n",
        "üìå **Note:**  \n",
        "Gradients are disabled during validation using `torch.no_grad()` to improve efficiency and prevent weight updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pxMyr159d5UW"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, test_loader, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            # Move batch to the selected device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Binary predictions\n",
        "            predicted = (outputs > 0.5).float()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bcKsHoLvTxk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoj068knVPN"
      },
      "source": [
        "## **üìå Full Training Process in PyTorch**\n",
        "\n",
        "Now that you understand the **Dataset Class, Model Class, Training Loop, and Validation Loop**, it's time to put everything together into a **full training process**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUK2taqBkUyR"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zryj9VCzkaHl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOguR6wwkmlr"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BT-TaJLL6isg"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets for training and testing\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create Dataloaders to train and test data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Y-oPSxlJOw"
      },
      "source": [
        "### Run full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgTf7gdlOQZ",
        "outputId": "733f700a-7eb8-4d8e-efc7-b8396ff33ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting Training...\n",
            "Epoch [5/50], Train Loss: 0.4855, Val Loss: 0.4531, Val Accuracy: 0.8860\n",
            "Epoch [10/50], Train Loss: 0.2758, Val Loss: 0.2747, Val Accuracy: 0.9211\n",
            "Epoch [15/50], Train Loss: 0.1630, Val Loss: 0.1877, Val Accuracy: 0.9561\n",
            "Epoch [20/50], Train Loss: 0.1170, Val Loss: 0.1462, Val Accuracy: 0.9561\n",
            "Epoch [25/50], Train Loss: 0.0948, Val Loss: 0.1235, Val Accuracy: 0.9561\n",
            "Epoch [30/50], Train Loss: 0.1043, Val Loss: 0.1103, Val Accuracy: 0.9649\n",
            "Epoch [35/50], Train Loss: 0.0731, Val Loss: 0.1036, Val Accuracy: 0.9561\n",
            "Epoch [40/50], Train Loss: 0.0647, Val Loss: 0.0977, Val Accuracy: 0.9649\n",
            "Epoch [45/50], Train Loss: 0.0584, Val Loss: 0.0934, Val Accuracy: 0.9561\n",
            "Epoch [50/50], Train Loss: 0.0553, Val Loss: 0.0897, Val Accuracy: 0.9649\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model, Criterion, Optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 10\n",
        "model =NN2Layer(input_dim, hidden_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Run Training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print('Starting Training...')\n",
        "for epoch in range(num_epochs):\n",
        "    # Train one epoch\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_accuracy = validate(model, criterion, test_loader, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvMxHD4nfTs"
      },
      "source": [
        "### Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1ftDlPPhniA6",
        "outputId": "cebc27b5-5437-446d-81b8-50920eae9f96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting results\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvSQimxq_3O"
      },
      "source": [
        "## Now you know how to use PyTorch for NNs :)\n",
        "\n",
        "\n",
        "![image.png](https://i.imgur.com/1xbDOQX.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDl5V6-7SOal"
      },
      "source": [
        "### **Contributed by: Yara Alzahrani, Mohamed Eltayeb**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}